\documentclass[mathserif, serif]{beamer}

%\documentclass[a4paper,11pt,onecolumn,twoside,openright,titlepage]{article}

\usepackage[T1]{fontenc}
\usepackage[polish]{babel}
\usepackage[utf8]{inputenc}
\usepackage{lmodern}
\usepackage{amsmath}
\usepackage[T1]{fontenc}
\usepackage[polish]{babel}
\usepackage[utf8]{inputenc}
\usepackage{lmodern}
\usepackage{hyperref}
\usepackage{float}
\usepackage{changepage}
\usepackage{pdflscape}
\usepackage{multirow}
\usepackage{tabularx}
\usepackage{array}
\usepackage{algorithmic}
\usepackage{tikz}
\usetikzlibrary{positioning}
\usetikzlibrary{arrows}
\usetikzlibrary{shapes}
\usepackage{pgfplots}
\usetikzlibrary{decorations.pathreplacing}
\selectlanguage{polish}
\usetikzlibrary{arrows.meta}

\author{Aleksander Sas}
\title{Sieci neuronowe rozpoznające trifony w procesie analizy mowy}
\usetheme{Warsaw}

\DeclareMathOperator*{\argmax}{\arg\max}   % rbp
\tikzstyle{hmm0}=[circle,thick,draw=gray!50,fill=gray!13,minimum size=4mm]
\tikzstyle{hmm}=[circle,thick,draw=gray!75,fill=gray!20,minimum size=6mm]
\tikzstyle{line} = [draw, -latex']


\begin{document}
	\begin{frame}
		\titlepage
	\end{frame}

	\begin{frame}
		Cele bronionej pracy magisterskiej:
		\begin{itemize}
			\item sprawdzenie możliwości wyuczenia sieci neuronowej rozpoznającej trifony,
			\item porównanie powyższej sieci z siecią rozpoznającą unifony,
			\item porównanie systemu wykorzystującego sieć neuronową z klasycznym systemem
			\item uzyskanie możliwie najwyższej skuteczności rozpoznawania.
		\end{itemize}
	\end{frame}

	\begin{frame}
		\frametitle{Etapy rozpoznawania mowy}
		
		\begin{figure}
			\scalebox{.65}{
				\begin{tikzpicture}[node distance = 1.7cm, auto]
				
				\tikzstyle{ArmBlok} = [rectangle, draw, fill=blue!20, text width=12em, text centered, rounded corners, minimum height=3em]
				\tikzstyle{model} = [ellipse, draw, fill=blue!20, text width=7em, text centered, rounded corners, minimum height=3em, node distance=5cm]
				\tikzstyle{data} = [draw, ellipse,fill=red!20, node distance=2cm,minimum height=2em]
				
				% Place nodes
				\node [data] (etap0) {Mowa};
				\node [ArmBlok,  below of=etap0] (etap1) {Zbieranie sygnału akustycznego};
				\node [ArmBlok,  below of=etap1] (etap2) { Ekstrakcja cech};
				\node [ArmBlok,  below of=etap2, fill=blue!40] (etap3) {Klasyfikacja stanów};
				\node [ArmBlok,  below of=etap3] (etap4) { Wyszukiwanie najlepszej ścieżki w modelu Markowa};
				\node [model, right of=etap3] (etap5) { Model językowy};
				\node [model,    left  of=etap2, fill=blue!40] (model_akustyczny) { Model akustyczny};
				\node [data,     below of=etap4] (etap6) {Rozpoznanie};
				\node [model,   right  of=etap6] (slownik) {Słownik};
				
				\path [line] (etap0) -- (etap1);
				\path [line] (etap1) -- (etap2);
				\path [line] (etap2) -- (etap3);
				\path [line] (etap3) -- (etap4);
				\path [line, dashed] (etap5) |- (etap4);
				\path [line] (etap4) -- (etap6);
				\path [line, dashed] (slownik) |- (etap4);
				\path [line, dashed] (model_akustyczny) |- (etap3);
				\path [line, dashed] (model_akustyczny) |- (etap4);
				
				\end{tikzpicture}
			}
		\end{figure}
	\end{frame}	

	\begin{frame}
		\frametitle{Model fonemu}
		
			\begin{itemize}
				\item Fonemy reprezentują dźwięki.
				\item Modelujemy je trzema stanami modelu Markowa.
				\item Dźwięki mogą mieć różną długość.
				\item Trifony są rozwinięciem koncepcji fonów, przykładowo $a-g+r$.
			\end{itemize}		
		
		\begin{figure}
			\scalebox{.8}{
				\begin{tikzpicture}[node distance=1.7cm]
				
				\begin{scope}
				\node [hmm] (hmm1) {$s_1$};
				\node [hmm, right of=hmm1] (hmm2) {$s_2$};
				\node [hmm, right of=hmm2] (hmm3) {$s_2$};
				
				\draw[thick,->,shorten >=1pt] (hmm1) to [out=0,in=180] (hmm2);
				\draw[thick,->,shorten >=1pt] (hmm2) to [out=0,in=180] (hmm3);
				
				\draw[thick,->] (hmm1.70) arc (-60:245:4mm);
				\draw[thick,->] (hmm2.70) arc (-60:245:4mm);
				\draw[thick,->] (hmm3.70) arc (-60:245:4mm);
				
				\draw[thick,<-,shorten <=1pt] (hmm1) -- +(180:1cm);
				\draw[thick,->,shorten <=1pt] (hmm3) -- +(0:1cm);
				\end{scope}
				
				\end{tikzpicture}
			}
		\end{figure}
	\end{frame}

	\begin{frame}
		\frametitle{Fonemy modelowane w systemie}
		
		\begin{itemize}
			\item Zamodelowano 40 fonemów.
			\item $40\times40\times40=64000$ możliwych trifonów.
			\item W praktyce wystąpiło 27005 różnych trifonów.
		\end{itemize}		
		
		\begin{table}
			\begin{tabular}{|c c c c c c c c|}
				\hline
				a  & o\~ & b & c & cz & ć & d & dz \\ 
				dź & dż & e & e\~ & f & g & g\^ & h \\
				i & j & k & k\^ & l & ł & m & n \\
				nn & ń & o & p  & r & s & sz & ś \\
				t & u & v & y & z & ź & ż & sil \\
				\hline
			\end{tabular}
		\end{table}
	\end{frame}


	\begin{frame}
		\frametitle{Mikstury Gaussowskie}
		\footnotesize
		\begin{itemize}
			\item Dla każdej ramki (wektora cech) potrzebujemy $P(o|s)$.
			\item W przyrodzie wszystko ma rozkład Gaussowski.
			\item Typowo 39-cio wymiarowe rozkłady.
		\end{itemize}
		
		\begin{figure}
			\scalebox{.8}{
				\begin{tikzpicture}
				\begin{axis}[
				axis lines = left
				]
				%Below the red parabola is defined
				\addplot [
				domain=0:20, 
				samples=100, 
				color=red,
				]
				{0.3 * 1/(2.5 * 2) * e ^ (-(x - 5)^2 / (2 * 2 ^ 2))};
				
				\addplot [
				domain=0:20, 
				samples=100, 
				color=blue,
				]
				{0.3 * 1/(2.5 * 4) * e ^ (-(x - 17)^2 / (2 * 4 ^ 2))};
				
				\addplot [
				domain=0:20, 
				samples=100, 
				color=yellow,
				]
				{0.4 * 1/(2.5 * 1.5) * e ^ (-(x - 10)^2 / (2 * 1.5 ^ 2))};
				
				\addplot [
				domain=0:20, 
				samples=100, 
				color=black,
				]
				{0.3 * 1/(2.5 * 2) * e ^ (-(x - 5)^2 / (2 * 2 ^ 2)) + 0.3 * 1/(2.5 * 4) * e ^ (-(x - 17)^2 / (2 * 4 ^ 2)) + 0.4 * 1/(2.5 * 1.5) * e ^ (-(x - 10)^2 / (2 * 1.5 ^ 2))};
				
				\end{axis}
				\end{tikzpicture}
			}
		\end{figure}
	\end{frame}

	\begin{frame}
		\frametitle{Sieci neuronowe przy rozpoznawaniu mowy}
		
	\begin{figure}
		\hspace*{-0.6cm}  
		\scalebox{.65}{
			\begin{tikzpicture}
			\tikzstyle{conv_layer} = [fill=black,fill=gray!20,draw=black, text centered]
			
			
			\begin{axis}[
			axis lines = left
			]
			%Below the red parabola is defined
			\addplot [
			domain=0:20, 
			samples=100, 
			color=red,
			]
			{0.3 * 1/(2.5 * 2) * e ^ (-(x - 5)^2 / (2 * 2 ^ 2))};
			
			\addplot [
			domain=0:20, 
			samples=100, 
			color=blue,
			]
			{0.3 * 1/(2.5 * 4) * e ^ (-(x - 17)^2 / (2 * 4 ^ 2))};
			
			\addplot [
			domain=0:20, 
			samples=100, 
			color=yellow,
			]
			{0.4 * 1/(2.5 * 1.5) * e ^ (-(x - 10)^2 / (2 * 1.5 ^ 2))};
			
			\addplot [
			domain=0:20, 
			samples=100, 
			color=black,
			]
			{0.3 * 1/(2.5 * 2) * e ^ (-(x - 5)^2 / (2 * 2 ^ 2)) + 0.3 * 1/(2.5 * 4) * e ^ (-(x - 17)^2 / (2 * 4 ^ 2)) + 0.4 * 1/(2.5 * 1.5) * e ^ (-(x - 10)^2 / (2 * 1.5 ^ 2))};
			
			\end{axis}
			
			%----------------------------------------------------------------------
			
			\draw[-{Latex[width=5mm]}] (7,3)--(9,3);
			
			%----------------------------------------------------------------------
			
			\def\w{1.5}		
			
			\def\x{10.0}	
			\def\y{2.5}				
			\pgfmathsetmacro{\X}{\x + \w};
			\pgfmathsetmacro{\Y}{\y + \w};
			\draw [fill=black,fill=gray!20,draw=black] (\x,\y) rectangle (\X,\Y);
			
			
			\def\x{10.25}	
			\def\y{2.25}				
			\pgfmathsetmacro{\X}{\x + \w};
			\pgfmathsetmacro{\Y}{\y + \w};
			\draw [fill=black,fill=gray!20,draw=black] (\x,\y) rectangle (\X,\Y);
			
			\def\x{10.5}	
			\def\y{2.0}				
			\pgfmathsetmacro{\X}{\x + \w};
			\pgfmathsetmacro{\Y}{\y + \w};
			\draw [fill=black,fill=gray!20,draw=black] (\x,\y) rectangle (\X,\Y) node [black,midway] {$11\times6$};
			
			
			\def\w{0.6}	
			\def\h{2.0}	
			\def\x{13.5}	
			\def\y{2.0}				
			\pgfmathsetmacro{\X}{\x + \w};
			\pgfmathsetmacro{\Y}{\y + \h};
			\draw [fill=black,fill=gray!20,draw=black] (\x,\y) rectangle (\X,\Y) node [black,midway, rotate=90] {$2400$};
			
			\draw (11.5,4.0) -- (13.5,3.0);
			\draw (12.0,2.0) -- (13.5,3.0);
			
			\def\w{0.6}	
			\def\h{1.5}	
			\def\x{15.5}	
			\def\y{2.25}				
			\pgfmathsetmacro{\X}{\x + \w};
			\pgfmathsetmacro{\Y}{\y + \h};
			\draw [fill=black,fill=gray!20,draw=black] (\x,\y) rectangle (\X,\Y) node [black,midway, rotate=90] {$|Q|$};
			
			\draw (14.2,4.0) -- (15.5,3.0);
			\draw (14.2,2.0) -- (15.5,3.0);
			\end{tikzpicture}
		}
	\end{figure}
		
	\end{frame}	

	\begin{frame}
		\frametitle{Plan przeprowadzonych eksperymentów}
		
		\begin{itemize}
			\item Przygotowanie korpusu treningowego dla sieci neuronowej.
			\item Budowa pełnego modelu klasycznego (model referencyjny).
			\item Budowa rodziny modeli klasycznych $M$ o ograniczonej liczbie stanów.
			\item Wyuczenie sieci neuronowych dla każdego modelu z rodziny $M$.
			\item Porównanie skuteczności zbudowanych modeli.
		\end{itemize}
	
	\end{frame}

	\begin{frame}
		\frametitle{Korpus \textit{Clarin}}
		
		\begin{itemize}
			\item Powszechnie dostępny korpus wypowiedzi studyjnych.
			\item Przygotowany prze Politechnikę Wrocławską (1http://mowa.clarin-pl.eu/korpusy/).
			\item 56 godzin (wliczając ciszę).
			\item 556 różnych mówców.
			\item Niestety zawiera liczne błędy w transkrypcjach.
		\end{itemize}
		
	\end{frame}

	\begin{frame}
		\frametitle{Przygotowanie korpusu treningowego}
		\small
		\begin{itemize}
			\item Wyznaczenie par $<wektor\_cech,stan\_modelu\_Markowa>$.
			\item Wymagane jest precyzyjne dopasowanie wektorów do stanów.
			\item Modele uczona są na danych treningowych ($99.3\%$ skuteczności)
		\end{itemize}
		
		\begin{figure}
			\scalebox{.8}{
			\begin{tikzpicture}
			
			\begin{scope}
			\tikzstyle{arch_part} = [rectangle, draw, text width=8em, text centered, rounded corners, minimum height=3em]
			\tikzstyle{arch_part_data} = [rectangle, draw,  fill=blue!20, text width=8em, text centered, rounded corners, minimum height=3em]
			\tikzstyle{arch_part_results} = [rectangle, draw,  fill=green!20, text width=8em, text centered, rounded corners, minimum height=3em]
			
			\def\l{-2.0}
			\def\c{0,0}
			\def\r{2.0}
			\def\t{6.5}
			
			\def\u{1.7}
			\def\d{-1.7}
			
			\node [arch_part_data] (clarin) at (\l, \c) {Korpus Clarin};
			
			\node [arch_part_data] (model_lang) at (\l, \u) {Model językowy};
			\path [line] (clarin) -- (model_lang);
			
			\node [arch_part_data] (model_acc) at (\l, \d) {Model akustyczny};
			\path [line] (clarin) -- (model_acc);
			
			\node [arch_part_data] (julius) at (\r, \c) {Julius};
			\path [line] (clarin) -- (julius);
			\path [line] (model_lang) -| (julius);
			\path [line] (model_acc) -| (julius);
			
			\node [arch_part_data] (match) at (\t, \c) {Dopasowanie};
			\path [line] (julius) -- (match);

			\end{scope}
			\end{tikzpicture}
		}
		\end{figure}
	\end{frame}

	\begin{frame}
		\frametitle{Budowa pełnego modelu klasycznego}
		
		\begin{itemize}
			\item Klasyczny model korzystający z mikstur Gaussowskich.
			\item 4192 stanów.
			\item Połnadzorowany algorytm Bauma-Welcha (HTK).
		\end{itemize}
		
		\begin{figure}
			\scalebox{.65}{
				\begin{tikzpicture}[node distance = 0.1cm, auto]
				
				\tikzstyle{model} = [ellipse, draw, fill=blue!20, text width=7em, text centered, rounded corners, minimum height=3em, node distance=5cm]
				
				\node [model] (Ini) {Inicjalizacja modelu};
				\node [model,   right = 1.0 cm of Ini] (E) {Dopasowanie ramek};
				\node [model,   below = 1.0 cm of E] (M) {Estymacja parametrów};
				\node [model,   right = 1.0 cm of M] (R) {Gotowy model akustyczny};
				
				\draw[thick,->,shorten >=1pt] (E) to [out=185,in=180,looseness=1.1] (M);
				\draw[thick,->,shorten >=1pt] (M) to [out=10,in=0,looseness=1.1] (E);
				\draw[thick,->,shorten >=1pt] (Ini) to [out=0,in=180,looseness=1.1] (E);
				\draw[thick,->,shorten >=1pt] (M) to [out=0,in=180,looseness=1.1] (R);

				
				\end{tikzpicture}
			}
		\end{figure}
	
	\end{frame}

	\begin{frame}
		\frametitle{Procedura budowy klasycznych modeli}
		\tiny
		\begin{figure}
			\begin{algorithmic}[1]
				
				\REQUIRE {$S =$ zbiór par $(wypowiedz, transkrypcja)$}
				
				\STATE $M_{acc} = Init(S)$				
				\FOR{$i = 1 \text{ to }3$}
				\STATE $M_{acc} = ReEstimate(M_{acc}, S)$
				\STATE $M_{acc} = ReEstimate(M_{acc}, S)$
				\STATE $M_{acc} = ReEstimate(M_{acc}, S)$
				\STATE $M_{acc} = ExtendGMM(M_{acc})$
				\ENDFOR			
				\STATE $M_{acc} = CreateTriFones(M_{acc})$
				\STATE $M_{acc} = TreeBasedClustering(M_{acc})$
				\FOR{$i = 4 \text{ to }12$}
				\STATE $M_{acc} = ReEstimate(M_{acc}, S)$
				\STATE $M_{acc} = ReEstimate(M_{acc}, S)$
				\STATE $M_{acc} = ReEstimate(M_{acc}, S)$
				\STATE $M_{acc} = ExtendGMM(M_{acc})$
				\ENDFOR			
				\STATE $M_{acc} = ReEstimate(M_{acc}, S)$
				\STATE $M_{acc} = ReEstimate(M_{acc}, S)$
				\STATE $M_{acc} = ReEstimate(M_{acc}, S)$
				\RETURN $M_{acc}$;
			\end{algorithmic}	
		\end{figure}
	\end{frame}

	\begin{frame}
		\frametitle{Budowa modeli o ograniczonej liczbie stanów}
		\begin{itemize}
			\item Rozbudowa modelu unifonowego do trifonowego.
			\item \textit{Tree based clustering} ogranicza liczbę klas abstrakcji.
			\item Przy pomocy zadanych parametrów sterujemy ograniczaniem modeli.
		\end{itemize}
	
		\begin{figure}[H]
			\scalebox{.65}{
			\begin{tikzpicture}[node distance=1.2cm]
			
			\begin{scope}
			
			\def\x{0.8}
			\def\w{\x * 5}
			\def\z{\x * 2}
			\def\y{1.4}
			\def\j{2.0}
			
			\draw[dotted] (-1,-4) rectangle (3.2,1);
			\draw[dotted] (4,-4) rectangle (6.3,1);
			\draw[dotted] (6.75,-4) rectangle (10.85,1);
			
			\node [hmm] (p1) {d-b+e};
			\node [hmm, right = \x cm of p1] (p2) {a-b+c};
			\node [hmm, below = \y cm of p2] (p3) {c-b+d};
			
			\node [hmm, right = \z cm of p3] (p4) {k-l+m};
			
			\node [hmm, right = \w cm of p2] (p5) {x-y+z};
			\node [hmm, right = \x cm of p5] (p6) {w-y+t};
			\node [hmm, below = \y cm of p5] (p7) {u-y+t};
			
			
			\draw [->] (p1) [out=270, in=140] to  (p3);
			\draw [->] (p2) [out=280, in=80] to  (p3);
			
			\draw [->] (p6) [out=270, in=40] to  (p7);
			\draw [->] (p5) [out=260, in=100] to  (p7);
			
			\node [hmm, below = \j cm of p3] (s1) {s1};
			\node [hmm, right = \x cm of s1] (s2) {s2};
			\node [hmm, right = \x cm of s2] (s3) {s3};
			\node [hmm, right = \x cm of s3] (s4) {s4};
			\node [hmm, right = \x cm of s4] (s5) {s5};
			
			\draw [->] (p3) [out=240, in=100] to (s1);
			\draw [->] (p3) [out=270, in=90]  to (s2);
			\draw [->] (p3) [out=300, in=130] to (s5);
			
			\draw [->] (p4) [out=240, in=80]  to (s1);
			\draw [->] (p4) [out=270, in=90]  to (s3);
			\draw [->] (p4) [out=300, in=100] to (s5);
			
			\draw [->] (p7) [out=240, in=50]  to (s1);
			\draw [->] (p7) [out=270, in=90]  to (s4);
			\draw [->] (p7) [out=300, in=80] to (s5);
			\end{scope}
			
			\end{tikzpicture}
		}
		\end{figure}
	\end{frame}

	\begin{frame}
		\frametitle{Otrzymane modele}
		\small
		\begin{figure}
			\begin{tabular}{|l|c|c|c|c|} \hline
				
				Nazwa modelu & \vtop{\hbox{\strut Min liczba}\hbox{\strut obserwacji}} &
				\vtop{\hbox{\strut Próg}\hbox{\strut poprawy}}& Liczba stanów & Skuteczność \\ \hline
				
				M\_TRI\_OPT   & 100   & 350 & 4192 & 83.44 \\
				M\_TRI         & 100   & 350 & 4192 & 81.58 \\
				M\_25000       & 25000 & 350 & 304  & 76.90 \\
				M\_29000       & 29000 & 350 & 269  & 77.75 \\
				M\_33000       & 33000 & 350 & 231  & 77.23 \\
				M\_37000       & 37000 & 350 & 214  & 77.13 \\
				M\_70000       & 70000 & 350 & 147  & 75.91 \\
				M\_180000     & 18000 & 350 & 122  & 75.17 \\
				M\_UNI         &  N/A  & N/A & 120  & 76.86 \\
				\hline
			\end{tabular}
		\end{figure}
	\end{frame}

	\begin{frame}
		\frametitle{Budowa sieci neuronowych}
		\small
		\begin{itemize}
			\item Sieć jest ściśle dopasowana do modelu akustycznego.
			\item Sieć dla każdej ramki z osobna wyznacz ppb wszystkich stanów.
			\item Sieć zwraca $P(s|o)$, potrzebujemy $P(o|s)$, korzystamy znowu z Bayesa.
		\end{itemize}
	
	\begin{figure}[H]
		\centering
		\begin{tikzpicture}
		
		\begin{scope}
		
		\tikzstyle{conv_layer} = [fill=black,fill=gray!20,draw=black, text centered]
		
		\node at (0.5,2.4){$64$ filtry};
		\node at (3.4,2.9){warstwa pełna + dropout $0.5$};
		\node at (6.8,2.4){warstwa pełna + softmax};
		
		\def\w{1.5}		
		
		\def\x{0.0}	
		\def\y{0.5}				
		\pgfmathsetmacro{\X}{\x + \w};
		\pgfmathsetmacro{\Y}{\y + \w};
		\draw [fill=black,fill=gray!20,draw=black] (\x,\y) rectangle (\X,\Y);
		
		
		\def\x{0.25}	
		\def\y{0.25}				
		\pgfmathsetmacro{\X}{\x + \w};
		\pgfmathsetmacro{\Y}{\y + \w};
		\draw [fill=black,fill=gray!20,draw=black] (\x,\y) rectangle (\X,\Y);
		
		\def\x{0.5}	
		\def\y{0.0}				
		\pgfmathsetmacro{\X}{\x + \w};
		\pgfmathsetmacro{\Y}{\y + \w};
		\draw [fill=black,fill=gray!20,draw=black] (\x,\y) rectangle (\X,\Y) node [black,midway] {$11\times6$};
		
		
		\def\w{0.6}	
		\def\h{2.0}	
		\def\x{3.5}	
		\def\y{0.0}				
		\pgfmathsetmacro{\X}{\x + \w};
		\pgfmathsetmacro{\Y}{\y + \h};
		\draw [fill=black,fill=gray!20,draw=black] (\x,\y) rectangle (\X,\Y) node [black,midway, rotate=90] {$2400$};
		
		\draw (1.5,2.0) -- (3.5,1.0);
		\draw (2.0,0.0) -- (3.5,1.0);
		
		\def\w{0.6}	
		\def\h{1.5}	
		\def\x{5.5}	
		\def\y{0.25}				
		\pgfmathsetmacro{\X}{\x + \w};
		\pgfmathsetmacro{\Y}{\y + \h};
		\draw [fill=black,fill=gray!20,draw=black] (\x,\y) rectangle (\X,\Y) node [black,midway, rotate=90] {$|Q|$};
		
		\draw (4.2,2.0) -- (5.5,1.0);
		\draw (4.2,0.0) -- (5.5,1.0);
		
		\end{scope}
		
		\end{tikzpicture}
	\end{figure}
	\end{frame}

	\begin{frame}
		\frametitle{Wpływ liczby stanów na skuteczność}
		
		\begin{figure}[H]
			\centering
			\begin{tikzpicture}			
			\begin{axis}[axis lines = left,	xlabel = Liczba stanów, ylabel = {1-WER [\%]},xmin=100,xmax=320,ymin=45,ymax=100,]
			
			\addplot[color=blue,mark=square,]
			coordinates {
				(122,81.55)(147,81.69)(214,83.34)(231,83.48)(269,72.07)(304, 57.42)
			};
			\addlegendentry{Modele neuronowe}
			
			\addplot[color=red,mark=square,]
			coordinates {
				(122,75.17)(147,75.91)(214,77.13)(231,77.23)(269,77.75)(304, 78.06)
			};
			\addlegendentry{Modele klasyczne}
			
			\end{axis}			
			\end{tikzpicture}
		\end{figure}
	\end{frame}

	\begin{frame}
		\frametitle{Wpływ liczby neuronów warstwy ukrytej na skuteczność}
		
		\begin{figure}[H]
			\centering
			\begin{tikzpicture}			
			\begin{axis}[axis lines = left,	xlabel = {Liczba neuronów} , ylabel = {1-WER [\%]},xmin=0,xmax=2500,ymin=80,ymax=85,]
			
			\addplot[color=red,mark=square,]
			coordinates {
				(300,81.36)(600,82.01)(1200,83.10)(2400, 83.02)
			};
			
			\end{axis}			
			\end{tikzpicture}
		\end{figure}
	\end{frame}

	\begin{frame}
		\frametitle{Wpływ innych czynników na skuteczność}
		\footnotesize
		\begin{tabular}{|l|c|c|c|c|c|} \hline
			\vtop{\hbox{\strut Funkcja}\hbox{\strut nieliniowości}} & \vtop{\hbox{\strut Dane}\hbox{\strut przemieszane}} & \vtop{\hbox{\strut Ppb}\hbox{\strut a priori}} & \vtop{\hbox{\strut Liczba}\hbox{\strut filtrów}} & \vtop{\hbox{\strut Liczba}\hbox{\strut neuronów}} & Skuteczność \\
			\hline
			recify        &  nie & tak & 64 & 2400 & 83.50  \\
			leaky rectify &  nie & tak & 64 & 2400 & 83.89 \\
			\hline
			leaky rectify &  nie & tak &32 & 1200 & 83.10 \\
			leaky rectify &  tak & tak &32 & 1200 & 83.64\\
			\hline
			leaky rectify &  tak & tak & 64 & 2400 & 84.71\\
			leaky rectify &  tak & nie & 64 & 2400 & 85.75\\
			\hline				
		\end{tabular}
	\end{frame}

	\begin{frame}
		\frametitle{Wnioski}
		
		\begin{itemize}
			\item Poprawa o $2.31\%$ (względna poprawa o $13.95\%$, $83.44\%$ vs $85.75\%$).
			\item Zwiększenie liczby rozpoznawanych stanów poprawiło skuteczność ($81.55\%$ vs $83.48\%$).
			\item Powyżej pewnej $231$ stanów gwałtowny spadek skuteczności.
			\item Dodanie prawdopodobieństwa a priori pogorszyło skuteczność.
			\item Pogłębianie sieci pogorszyło skuteczność.
		\end{itemize}
	
	\begin{exampleblock}{}
		\textbf{Wyniki są obiecujące.}
	\end{exampleblock}
	
	\end{frame}

	\begin{frame}
		\frametitle{Możliwości dalszego rozwoju}
		
		\begin{itemize}
			\item Budowa na większym korpusie.
			\item Próby z innymi architekturami.
			\item Uczenie warstw pojedynczo (klucz do prawdziwie głębokich sieci ?).
		\end{itemize}
	\end{frame}

\begin{frame}
	\huge
	\begin{exampleblock}{}
		\textbf{Dziękuję za uwagę.}
	\end{exampleblock}

\end{frame}

\end{document}