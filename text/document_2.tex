\documentclass[11pt]{article}

\usepackage{amsmath}
\usepackage[T1]{fontenc}
\usepackage[polish]{babel}
\usepackage[utf8]{inputenc}
\usepackage{lmodern}
\usepackage{tikz}
\usetikzlibrary{positioning}
\usetikzlibrary{arrows}
\usepackage{hyperref}
\usepackage{float}
\usepackage{changepage}
\usepackage{pdflscape}
\usepackage{multirow}
\usepackage{tabularx}
\usepackage{array}
\hypersetup{
	colorlinks,
	citecolor=black,
	filecolor=black,
	linkcolor=black,
	urlcolor=black
}
\usetikzlibrary{shapes,arrows}
\selectlanguage{polish}

\author{Aleksander Sas}
\title{Szkic artykułu}
\frenchspacing

\newcolumntype{K}[1]{>{\centering\arraybackslash}p{#1}}
\newtheorem{mydef}{Definicja}
\DeclareMathOperator*{\argmax}{\arg\max}   % rbp
\newcounter{BlockCounter}
\newcommand{\labelBlock}[1]{%
	\smash{\raisebox{15pt}{\refstepcounter{BlockCounter}\hypertarget{#1}{}\label{#1}}}%
	(\theBlockCounter)%
}
\newcommand{\refBlock}[1]{%
	\hyperref[#1]{\ref*{#1}}% (see p. 18 of the hyperref manual)
}

\begin{document}

% Define block styles
\tikzstyle{ArmBlok} = [rectangle, draw, fill=blue!20, text width=10em, text centered, rounded corners, minimum height=4em]
\tikzstyle{ArmBlok2} = [rectangle, draw, fill=blue!20, text width=10em, text centered, rounded corners, minimum height=4em, node distance=5cm]
\tikzstyle{hmm0}=[circle,thick,draw=gray!50,fill=gray!13,minimum size=4mm]
\tikzstyle{hmm}=[circle,thick,draw=gray!75,fill=gray!20,minimum size=6mm]
\tikzstyle{hmm2}=[circle,thick,draw=gray!75,fill=gray!20,minimum size=10mm]
\tikzstyle{model} = [ellipse, draw, fill=blue!20, text width=6em, text centered, rounded corners, minimum height=4em, node distance=5cm]
\tikzstyle{block} = [rectangle, draw, fill=blue!20, text width=5em, text centered, rounded corners, minimum height=4em]
\tikzstyle{line} = [draw, -latex']
\tikzstyle{data} = [draw, ellipse,fill=red!20, node distance=2cm,minimum height=2em]

\maketitle
\tableofcontents

\section{Wprowadzenie - opis problemu}
	\textbf{Automatyczne rozpoznawanie mowy}, w skrócie \textbf{ARM}, polega na rozpoznaniu i zapisaniu nagranych słów. Jest to coraz częściej i powszechniej stosowana technologia, która znajduje szerokie zastosowanie w motoryzacji, urządzeniach mobilnych, administracji państwowej i medycznej. Jest szczególnie przydatna przy sporządzani opisów, tekstowych i protokołowaniu wszelkiego rodzaju obrad. Systemy do rozpoznawanie mowy działają na dwa sposoby
	\begin{itemize}
		\item offline, w którym system wczytuje zbiór nagrań dźwiękowych i dla każdego z nich generuje transkrypcję
		\item online, w którym system na bieżąco rejestruję dźwięk i wypisuje transkrypcję.
	\end{itemize}
	Oba tryby wymagają możliwie najlepszej skuteczności rozpoznawania, jednak tryb online jest bardziej wymagający, gdyż dodatkowo wymaga szybkiego działania. Rozpoznawanie w trybie online powinno się odbywać w czasie zbliżony do rzeczywistego. 
	\\
	Rozwój kart graficznych i pojawienie się technologii CUDA zaowocowało w ostatnim dziesięcioleciu szybkim rozwojem sieci neuronowych, które w wielu problemach klasyfikacji radzą sobie znacznie lepiej niż wcześniej stosowanie algorytmy. Coraz więcej badaczy próbuje stosować sieci neuronowe w celu poprawy jakości systemów rozpoznających mowę. Można spotkać wiele różnych konfiguracji, zarówno łączących konwencjonalne systemy, jaki i autonomiczne sieci rekurencyjne.
	\\
	Celem niniejszej pracy magisterskiej jest przetestowanie możliwości wykorzystania sieci neuronowych w procesie rozpoznawania mowy. Duży nacisk położony jest na możliwość rozpoznawanie trifonów z ograniczonym kontekstem, co jest moim rozwinięciem podejścia spotykanego w wielu publikacjach. W pracy zbadano wpływ liczby rozpoznawanych trifonów na skuteczność rozpoznawania mowy.
	
\section{Omówienie istniejących podejść}
	Klasyczne podejście do rozpoznawania mowy, opierające się na wykorzystaniu ukrytych modli markowa oraz wielowymiarowych mikstur gaussowskich, zostało opisane w \cite{book1}. 
	\\
	Autorzy \cite{article1} wykorzystali konwolucyjne sieci neuronowe oraz bramki LSTM do modelowania fonów. W tym podejściu, wyjście sieci rozpoznającej wszystkie trifony jest traktowane, jako wejście do modelu Markova. 
	
	Tutaj znajdzie się krótki spis książek i publikacji dotyczących podobnych zagadnień.

\section{Proces automatycznego rozpoznawania mowy (ARM) }

	\begin{figure}[H]
		\centering
		\begin{tikzpicture}[node distance = 2cm, auto]
		% Place nodes
		\node [data] (etap0) {Mowa};
		\node [ArmBlok,  below of=etap0] (etap1) {\labelBlock{zbieranie_sygnalu} sygnału akustycznego};
		\node [ArmBlok,  below of=etap1] (etap2) {\labelBlock{ekstrakcja_cech} Ekstrakcja cech};
		\node [ArmBlok,  below of=etap2] (etap3) {\labelBlock{klasyfikator} Klasyfikacja stanów};
		\node [ArmBlok,  below of=etap3] (etap4) {\labelBlock{lancuch_markova} Wyszukiwanie najlepszej ścieżki w modelu Markova};
		\node [ArmBlok2, right of=etap3] (etap5) {\labelBlock{n_gramy} Estymacja prawdopowobieństw słów};
		\node [model,    right of=etap2] (model_jezykowy) {Model językowy};
		\node [model,    left  of=etap2] (model_akustyczny) {\labelBlock{model_akustyczny} Model językowy};
		\node [data,     below of=etap4] (etap6) {Rozpoznanie};
		\node [model,   right  of=etap6] (slownik) {\labelBlock{slownik} Słownik};
		
		\path [line] (etap0) -- (etap1);
		\path [line] (etap1) -- (etap2);
		\path [line] (etap2) -- (etap3);
		\path [line] (etap3) -- (etap4);
		\path [line] (etap5) |- (etap4);
		\path [line] (etap4) -- (etap6);
		\path [line, dashed] (model_jezykowy) -- (etap5);
		\path [line, dashed] (slownik) |- (etap4);
		\path [line, dashed] (model_akustyczny) |- (etap3);
		\path [line, dashed] (model_akustyczny) |- (etap4);
		
		\end{tikzpicture}
		\caption{Etapy automatycznego rozpoznawania mowy}
		\label{fig:ARM_schemat}
	\end{figure}

	\textbf{Automatyczne rozpoznawanie mowy} możemy formalnie zdefiniować, jako znajdowanie ciągu słów $\hat{W}$ nad pewnym alfabetem $\Sigma$, o maksymalnym prawdopodobieństwie, pod warunkiem obserwacji $O$.
	
	\begin{equation}
		\hat{W}=\argmax_{W \in \Sigma^{*}}{P(W \mid O)}
		\label{equation:ASR_definicja1}
	\end{equation}
	
	Niestety wyliczanie formuły \ref{equation:ASR_definicja1} okazuję się niemożliwe do wykonania, ale korzystając ze wzory Bayesa możemy dojść do postaci \ref{equation:ASR_definicja2}, która jest już wygoda do obliczenia.
	
	\begin{equation}
		\hat{W}=\argmax_{W \in \Sigma^{*}}{P(W \mid O)} = \argmax_{W \in \Sigma^{*}}{\frac{P(O \mid W)P(W)}{P(O)}} = \argmax_{W \in \Sigma^{*}}{P(O \mid W)P(W)}
		\label{equation:ASR_definicja2}
	\end{equation}
	
	Ostatnie przejście wynika, z faktu, że $P(O)$ się nie zmienia.
	Implementując formułę \ref{equation:ASR_definicja2} możemy wydzielić 5 kluczowych etapów, są one zilustrowane na rysunku \ref{fig:ARM_schemat}. Opis poszczególnych etapów znajduje się w kolejnych podrozdziałach.
	\\
	Pierwszy etap, określony jako \textit{Zbieranie sygnału akustycznego} (blok \refBlock{zbieranie_sygnalu} na rysunku \ref{fig:ARM_schemat} ), jest realizowany sprzętowo poprzez peryferyjne urządzenia. Obejmuje analogowe przetwarzanie sygnału, cyfryzację oraz opcjonalny post-processing wykonywany przez kartę dźwiękową. Na tym etapie ważne jest, aby dostroić poziom dźwięku, tak aby uniknąć przesterowań, dobrać częstotliwość próbkowania i zakres częstotliwości. Niepoprawna konfiguracja tego etapu, może skutkować zakłóceniami oraz wycięciem cech, które mogą być istotne na kolejnym etapie, a w konsekwencji obniżeniem skuteczności rozpoznawania. W niniejszej pracy wykorzystany był gotowy, powszechnie dostępny korpus nagrań (patrz rozdział \ref{sec:opis_danych}), dlatego nie będę się skupiał na tym etapie.

	\subsection{ Fony }
	\label{sec:Phones}
		\begin{figure}[H]
			\centering
			\begin{tikzpicture}[node distance=1.7cm]
			
			\begin{scope}
			\node [hmm] (hmm1) {$s_1$};
			\node [hmm, right of=hmm1] (hmm2) {$s_2$};
			\node [hmm, right of=hmm2] (hmm3) {$s_2$};
			
			\draw[thick,->,shorten >=1pt] (hmm1) to [out=0,in=180] (hmm2);
			\draw[thick,->,shorten >=1pt] (hmm2) to [out=0,in=180] (hmm3);
			
			\draw[thick,->] (hmm1.70) arc (-60:245:4mm);
			\draw[thick,->] (hmm2.70) arc (-60:245:4mm);
			\draw[thick,->] (hmm3.70) arc (-60:245:4mm);
			
			\draw[thick,<-,shorten <=1pt] (hmm1) -- +(180:1cm);
			\draw[thick,->,shorten <=1pt] (hmm3) -- +(0:1cm);
			\end{scope}
			
			\end{tikzpicture}
			\caption{Reprezentacja fonów}
			\label{fig:fon_hmm}
			
		\end{figure}

		Fony są podstawową koncepcją przy modelowaniu dźwięków w mowie, będącą rozszerzeniem pojęcia głoski. Typowo rozróżniają dźwięczne i bezdźwięczne warianty głosek oraz wprowadzają nowe dźwięki, takie jak przykładowo \textit{cisza}. W tabeli \ref{tab:phone_list} znajduje się lista fonów zamodelowanych w wykorzystanych modelach akustycznych, łącznie jest ich 40. Słowa, które mają być rozpoznawane przez system muszą mieć przypisaną transkrypcję na fony. Lista słów wraz z transkrypcją znajduje się w \textit{słowniku} (blok \refBlock{slownik} na rysunku \ref{fig:ARM_schemat}).
		\\
		Lingwistyka <<?>>
		\\
		Parametry modelujące wszystkie rozpoznawane fony są częścią \textit{modelu akustycznego} (blok \refBlock{model_akustyczny} na rysunku \ref{fig:ARM_schemat}). 

		\begin{figure}
			\begin{tabular}{|K{1cm}K{1cm}K{1cm}K{1cm}K{1cm}K{1cm}K{1cm}K{1cm}|}
				\hline
				a  & o\~ & b & c & cz & ć & d & dz \\ 
				dź & dż & e & e\~ & f & g & g\^ & h \\
				i & j & k & k\^ & l & ł & m & n \\
				nn & ń & o & p  & r & s & sz & ś \\
				t & u & v & y & z & ź & ż & sil \\
				\hline
			\end{tabular}
			\caption{\label{tab:phone_list}Lista modelowanych fonów}
		\end{figure}
 

	\subsection{ Modelowanie fonów, modele kontekstowe i bezkontekstrowe }
		
		Przy modelowaniu fonów wyróżnia się trzy fazy:
		\begin{itemize}
			\item początkową, podczas której aparat mowy zmienia swój kształt
			\item środkową, podczas której aparat mowy jest już w ustabilizowanej pozycji
			\item końcową, podczas której aparat mowy przechodzi do układu dla kolejnego fonu, ale dźwięk jaki wydaje jest jeszcze bliższy aktualnemu fonowi. 
		\end{itemize}
		Uwzględniając powyższe spostrzeżenia, wszystkie fony modeluje się za pomocą trzech stanów, tak jak na rysunku \ref{fig:fon_hmm}. Ze stanu można przejść jedynie do następnego stanu lub powrócić do samego siebie. Dzięki przejściu zwrotnemu, możliwe jest modelowanie dźwięków o różnej długości. 
		\\
		Rozwinięciem fonów są \textbf{tri-fony}, uwzględniają one lewy i prawy kontekst poprzez dodanie informacji o fonach stojących obok. Typowo tri-fony zapisuje się zgodnie z notacją na rysunku \ref{fig:tri-fony_notacja}, gdzie \textit{a} jest poprzednim fonem, \textit{b} aktualnym, natomiast \textit{c} następnym. 
		
		\begin{figure}[H]
			\begin{center}
			{a-b+c}
			\end{center}
			\caption{Konwencja zapisu tri-fonów}
			\label{fig:tri-fony_notacja}
		\end{figure}
	
		W języku polskim niektóre głoski różnie się wymawia w zależności od kontekstu, czyli fonów stojących obok. Przykładowo, inaczej brzmi głoska \textit{w} w słowie \textit{wersja}, gdzie jest dźwięczna, a inaczej w zwrocie \textit{w pracy}, gdzie jest bezdźwięczna i bardziej przypomina głoskę \textit{f}. Model tri-fonowy pozwala na uchwycenie takiej różnicy, dzięki czemu umożliwia osiągnięcie wyższej skuteczności niż model uni-fonowy.
		\\
		Należy zauważyć, że korzystając z \textit{tri-fonów} zamiast \textit{uni-fonów} wprowadzamy dodatkową informację, zarówno do modelu językowego, jak i do modelu akustycznego, ale jednocześnie znacznie zwiększamy liczbę parametrów do estymacji i czas działania silnika rozpoznającego. W modelu \textit{tri-fonowym} występuje $O(n^3)$ tri-fonów, gdzie $n$ to liczba fonów w modelu uni-fonowym.  
		
	\subsection{ Rozpoznawanie }
		Ten rozdział ma na pokazać, jak wcześniej opisane elementy składają się na działający system do rozpoznawani.
	\subsection{ Ekstrakcja cech }
	\label{sec:Feature_vec}
	Tutaj omówić cechy MFCC i MFSC i krótko wspomnieć o innych np PLP, RASTA-PLP.
	

\section {Rozpoznawanie mowy z zastosowaniem ukrytych modeli markowa}
	\label{sec:ASR_HMM}
    \subsection{Ukryte modele Markova - definicja}
    
	    \textbf{Ukryte modele Markova}, w skrócie \textbf{HMM}, to automat, który przechodzi pomiędzy stanami z pewnym prawdopodobieństwem $p1$ i wraz z każdym przejściem, emituje obserwację z prawdopodobieństwem $p2$. Formalnie HMM można zdefiniować jako krotkę \ref{equation:HMM_def}.
	    
	    \begin{equation}
		    HMM = (Q, O, A, B, q_0, q_F)
		    \label{equation:HMM_def}
	    \end{equation}
	    gdzie
	    \begin{align*}
		    \mathbf{Q}=\{q_1, q_2,\ldots,q_n\} & &&  \text{Zbiór stanów automatu} \\
	 	    \mathbf{O}=\{o_1, o_2,\ldots,o_k\} & &&  \text{Zbiór obserwacji} \\
	 	    \mathbf{A} =
	 	    \left| \begin{array}{ccc}
		 	    a_{1,1} & \ldots & a_{1,n} \\
		 	    \vdots  & \ddots & \vdots\\
		 	    a_{n,1} & \ldots & a_{n,n}
	 	    \end{array} \right|
												 	    & &&  \text{Macierz przejścia pomiędzy stanami} \\
												 	    & && \\
	 	    \mathbf{B}=\{B_1(o),\ldots,B_n(o)\},o \in O & && \text{zbiór rozkłądów prawdopodobieństwa emisji} \\ 
													 	& && \text{obsetwacji \textit{o} w stanie \textit{i}} \\
		 	\mathbf{q_0, q_F}				  & && \text{stany początkowy i końcowy}
	    \end{align*}
	    
    	
	    	
	   \subsubsection{Modele Markova}
	   \subsubsection{Algorytmy Viterbiego}
		   Algorytmy Viterbiego sa dynamicznymi algorytmami do znajdowania najbardziej prawdopodobnej ścieżki w automacie oraz prawdopodobieństwa stanu $s_i$ po $t$ krokach. 
		   
		   \begin{itemize}
			   	\item Aby znaleźć najbardziej prawdopodobną ścieżkę, należy skorzystać z równania \ref{equation:viterbi_path}.
			   	\item Aby znaleźć prawdopodobieństwo stanu po $k$ krokach, należy skorzystać z równania \ref{equation:viterbi_node}.
		   \end{itemize}
	   
		   \begin{equation}
		   P_t^q=\max_{q \in Q} \bigg( P_{t-1}^q\cdot a_{q,w}\cdot b_q(o) \bigg)
		   \label{equation:viterbi_path}
		   \end{equation}
		   
		   \begin{equation}
		   P_t^q=\sum_{q \in Q} \bigg( P_{t-1}^q\cdot a_{q,w}\cdot b_q(o) \bigg)
		   \label{equation:viterbi_node}
		   \end{equation}
		   
		   \begin{figure}[H]
		   	\centering
		   	\begin{tikzpicture}[node distance=1.7cm]
		   	
		   	\begin{scope}
		   	\node [hmm] (hmm1) {$s_1$};
		   	\node[left] at (hmm1.west) {$P_{t-1}^{s1}$};
		   	
		   	\node [hmm, below of=hmm1] (hmm2) {$s_2$};
		   	\node[left] at (hmm2.west) {$P_{t-1}^{s2}$};
		   	
		   	\node [hmm, below of=hmm2] (hmm3) {$s_3$};
		   	\node[left] at (hmm3.west) {$P_{t-1}^{s3}$};
		   	
		   	\node [hmm, below of=hmm3] (hmm4) {$s_4$};
		   	\node[left] at (hmm4.west) {$P_{t-1}^{s4}$};
		   	
		   	\node [hmm, below of=hmm4] (hmm5) {$s_5$};
		   	\node[left] at (hmm5.west) {$P_{t-1}^{s5}$};
		   	
		   	\node [hmm, right = 3.5 cm of hmm3] (hmm6) {$s_3$};
		   	\node[right] at (hmm6.east) {$P_{t}^{s3}$};
		   	
		   	\draw [->] (hmm1) [out=0, in=140]  to node[midway,right,rotate=0] {$a_{s1,s3}$} (hmm6);
		   	\draw [->] (hmm2) [out=0, in=160]  to node[midway,above,rotate=0] {$a_{s2,s3}$} (hmm6);
		   	\draw [->] (hmm3) [out=0, in=180]  to node[midway,above,rotate=0] {$a_{s3,s3}$} (hmm6);
		   	\draw [->] (hmm4) [out=0, in=200]  to node[midway,above,rotate=0] {$a_{s4,s3}$} (hmm6);
		   	\draw [->] (hmm5) [out=0, in=220]  to node[midway,right,rotate=0] {$a_{s5,s3}$} (hmm6);
		   	
		   	
		   	\end{scope}
		   	
		   	\end{tikzpicture}
		   	\caption{Algorytmy Viterbiego}
		   	\label{fig:viterbi}
		   	
		   \end{figure}
		   
	   \subsubsection{Algorytm Bauma-Welcha}
	   \subsubsection{Estymacja parametrów rozkładu normalnego}
	
    \subsection{Modelowanie fonetyki z wykorzystaniem HMM }
    W klasycznych systemach rozpoznających mowę, wykorzystujących ukryte modele Markova, zbiór stanów reprezentuje fony. Każdy fon ma trzy stany w HMM, tak jak opisano w rozdziale \ref{sec:Phones}. Zbiorem obserwacji są wektory cech wyznaczane zgodnie z opisem w rozdziale \ref{sec:Feature_vec}. Przejścia pomiędzy stanami jednego fonemu są zgodne z opisem z rozdziału \ref{sec:Phones}, natomiast przejścia pomiędzy różnymi fonami są tworzone na podstawie słownika (blok \refBlock{slownik} na rysunku \ref{fig:ARM_schemat}). Dla każdego słowa generowany jest ciąg stanów odpowiadający kolejnym fonemom, z których składa się słowo. 
    
    \begin{figure}[H]
    	\centering
		\begin{tabular}{|c|}
			\hline
			W = "jabłko" = \{j a p ł k o\} \\ 
	
			\begin{tikzpicture}[node distance=1.7cm]
			
				\begin{scope}
				
				\def\x{0.65}
				\def\y{1.0}
				\def\z{2.5}
				
				\node [hmm0] (hmm1) {};
				\node [below] at (hmm1.south) {$j_1$};
				
				\node [hmm0, right = \x cm of hmm1] (hmm2) {};
				\node [below] at (hmm2.south) {$j_2$};
				
				\node [hmm0, right = \x cm of hmm2] (hmm3) {};
				\node [below] at (hmm3.south) {$j_3$};
				
				
				\node [hmm0, right = \y cm of hmm3] (hmm4) {};
				\node [below] at (hmm4.south) {$a_1$};
				
				\node [hmm0, right = \x cm of hmm4] (hmm5) {};
				\node [below] at (hmm5.south) {$a_2$};
				
				\node [hmm0, right = \x cm of hmm5] (hmm6) {};
				\node [below] at (hmm6.south) {$a_3$};
				
				
				\node [hmm0, right = \y cm of hmm6] (hmm7) {};
				\node [below] at (hmm7.south) {$p_1$};
				
				\node [hmm0, right = \x cm of hmm7] (hmm8) {};
				\node [below] at (hmm8.south) {$p_2$};
				
				\node [hmm0, right = \x cm of hmm8] (hmm9) {};
				\node [below] at (hmm9.south) {$p_3$};
				
				
				
				
				\node [hmm0, below = \z cm of hmm9] (hmm10) {};
				\node [below] at (hmm10.south) {$ł_1$};
				
				\node [hmm0, left = \x cm of hmm10] (hmm11) {};
				\node [below] at (hmm11.south) {$ł_2$};
				
				\node [hmm0, left = \x cm of hmm11] (hmm12) {};
				\node [below] at (hmm12.south) {$ł_3$};
				
				
				\node [hmm0, left = \y cm of hmm12] (hmm13) {};
				\node [below] at (hmm13.south) {$k_1$};
				
				\node [hmm0, left = \x cm of hmm13] (hmm14) {};
				\node [below] at (hmm14.south) {$k_2$};
				
				\node [hmm0, left = \x cm of hmm14] (hmm15) {};
				\node [below] at (hmm15.south) {$k_3$};
				
				
				\node [hmm0, left = \y cm of hmm15] (hmm16) {};
				\node [below] at (hmm16.south) {$o_1$};
				
				\node [hmm0, left = \x cm of hmm16] (hmm17) {};
				\node [below] at (hmm17.south) {$o_2$};
				
				\node [hmm0, left = \x cm of hmm17] (hmm18) {};
				\node [below] at (hmm18.south) {$o_3$};
				
				
				
				\draw[thick,->,shorten >=1pt] (hmm1) to [out=0,in=180] (hmm2);
				\draw[thick,->,shorten >=1pt] (hmm2) to [out=0,in=180] (hmm3);
				
				\draw[thick,->,shorten >=1pt] (hmm3) to [out=0,in=180] (hmm4);
				
				\draw[thick,->,shorten >=1pt] (hmm4) to [out=0,in=180] (hmm5);
				\draw[thick,->,shorten >=1pt] (hmm5) to [out=0,in=180] (hmm6);
				
				\draw[thick,->,shorten >=1pt] (hmm6) to [out=0,in=180] (hmm7);
				
				\draw[thick,->,shorten >=1pt] (hmm7) to [out=0,in=180] (hmm8);
				\draw[thick,->,shorten >=1pt] (hmm8) to [out=0,in=180] (hmm9);
				
				\draw[thick,->,shorten >=1pt] (hmm9) to [out=0,in=0,looseness=1.1] (hmm10);
				
				\draw[thick,->,shorten >=1pt] (hmm10) to [out=180,in=0] (hmm11);
				\draw[thick,->,shorten >=1pt] (hmm11) to [out=180,in=0] (hmm12);
				
				\draw[thick,->,shorten >=1pt] (hmm12) to [out=180,in=0] (hmm13);
				
				\draw[thick,->,shorten >=1pt] (hmm13) to [out=180,in=0] (hmm14);
				\draw[thick,->,shorten >=1pt] (hmm14) to [out=180,in=0] (hmm15);
				
				\draw[thick,->,shorten >=1pt] (hmm15) to [out=180,in=0] (hmm16);
				
				\draw[thick,->,shorten >=1pt] (hmm16) to [out=180,in=0] (hmm17);
				\draw[thick,->,shorten >=1pt] (hmm17) to [out=180,in=0] (hmm18);
				
		
				\draw[thick,->] (hmm1.70) arc (-60:245:4mm);
				\draw[thick,->] (hmm2.70) arc (-60:245:4mm);
				\draw[thick,->] (hmm3.70) arc (-60:245:4mm);
				
				\draw[thick,->] (hmm4.70) arc (-60:245:4mm);
				\draw[thick,->] (hmm5.70) arc (-60:245:4mm);
				\draw[thick,->] (hmm6.70) arc (-60:245:4mm);
				
				\draw[thick,->] (hmm7.70) arc (-60:245:4mm);
				\draw[thick,->] (hmm8.70) arc (-60:245:4mm);
				\draw[thick,->] (hmm9.70) arc (-60:245:4mm);
				
				
				
				\draw[thick,->] (hmm10.110) arc (240:-65:4mm);
				\draw[thick,->] (hmm11.110) arc (240:-65:4mm);
				\draw[thick,->] (hmm12.110) arc (240:-65:4mm);
				
				\draw[thick,->] (hmm13.110) arc (240:-65:4mm);
				\draw[thick,->] (hmm14.110) arc (240:-65:4mm);
				\draw[thick,->] (hmm15.110) arc (240:-65:4mm);
				
				\draw[thick,->] (hmm16.110) arc (240:-65:4mm);
				\draw[thick,->] (hmm17.110) arc (240:-65:4mm);
				\draw[thick,->] (hmm18.110) arc (240:-65:4mm);
				
				\draw[thick,<-,shorten <=1pt] (hmm1) -- +(180:1cm);
				\draw[thick,->,shorten <=1pt] (hmm18) -- +(180:1cm);
				\end{scope}			
			\end{tikzpicture} \\
			
			\hline
		\end{tabular}
    	\caption{sss}
    	\label{fig:xxx}
    	
    \end{figure}
    
    
       \subsubsection{ Modele bezkontekstowe i kontekstowe}
       \subsubsection{ Metody redukcji liczby stanów modeli kontekstowych }	

\section{N-gramowy model językowy}
Dosłownie kilka słów o n-gramach i wygładzaniu (to nie jest temat tej pracy)
    \subsection{ Rodzaje modeli językowych }
      Omówienie modeli stochastycznych, gramatycznych, moodeli językowych wykorzystujących sieci głębokiego uczenia (krótko)
    \subsection{ Estymacja parametrów modelu językowego na podstawie korpusu tekstów }
    \subsection{ Metody wygładzania stochastycznych modeli językowych }


\section{Rozpoznawanie mowy z wykorzystaniem sieci neuronowych}
	\label{sec:ASR_NN}
	\subsection{Sieć jako estymator prawdopodobieństw \textit{aposteriori} stanów }
	\subsection{Sieć jako generator cech dla procesu rozpoznawania }
	\subsection{Zastosowanie sieci DNN w ARM}
	\subsection{Zastosowanie sieci konwolucyjnych w ARM}
	\subsection{Skuteczność ARM przy zastosowaniu sieci neuronowych}
	
	Ten rozdział ma na pokazać, jak wcześniej opisane elementy składają się na działający system do rozpoznawani.

\section{ Zastosowanie modelowania fonemów z ograniczonym kontekstem w ASR }	
	Wykorzystując ukryte modele Markova, tak jak opisano w rozdziale \ref{sec:ASR_HMM}, wymaga policzenia, dla każdej ramki, prawdopodobieństwa każdego ze zdefiniowanych fonemów. Wykorzystując tri-fony przy rozpoznawaniu mowy trzeba zdefiniować $O(\sigma^3)$ modeli. Jednak tylko niektóre z tri-fonów o wspólnym środkowym fonie różnią się w istotny sposób. Oczywiście wraz ze wzrostem liczby fonemów, rośnie liczba obliczeń, które trzeba wykonać, co ma negatywny wpływ na szybkość rozpoznawania. Ponadto, przy wykorzystaniu sieci neuronowych zgodnie z podejściem opisanym w rozdziale \ref{sec:ASR_NN} trzeba wytrenować więcej parametrów, co z kolei, w ogóle utrudnia lub wręcz uniemożliwia proces uczenia. Aby ograniczyć negatywny wpływ dużej liczby fonemów, zastosowano technikę opisaną w rozdziale \ref{sec:tri-fone_mapping}. Dzięki niej można było znacznie ograniczyć szerokość warstwy wyjściowej, które jest równa liczbie fizycznych fonemów.
	
	\subsection{ Problemy wynikające z zastosowania kontekstowych modeli fonemów }
	\subsection{ Definicja modelu z ograniczonym kontekstem }
		\label{sec:tri-fone_mapping}
		Korzystając ze spostrzeżenia, że tylko niektóre tri-fony o wspólnym środkowym fonie istotnie się różnią, można zastosować mechanizm współdzielenia \textit{fizycznych modeli} przez wiele tri-fonów. Poprzez \textit{fizyczne tri-fony} będziemy tu rozumieć modele, które mają bezpośrednio zdefiniowane parametry, czyli przypisane stany modelu Markova oraz macierz przejścia pomiędzy nimi. Poprzez \textit{tri-fony wirtualne} będziemy rozumieć modele, które są zdefiniowane poprzez jakiś tri-fon fizyczny. Innymi słowy, istnieje mapowanie z tri-fonu wirtualnego na tri-fon fizyczny. Rysunek \ref{fig:virtual_phisical_tri-phones} pokazuje przykładowe mapowanie. Znajdujące się na nim tri-fony $d-b+d$, $k-l+m$ oraz $u-y+t$ sa fizyczne, natomiast $d-b+e$, $a-b+c$, $x-y+z$ oraz $d-y+t$ sa wirtualne. Ponadto fizyczne modele mogą współdzielić stany, przy czym drugi, środkowy stan jest zawsze współdzielony przez wszystkie tri-fony o takim samym środkowym fonie. Oba mechanizmy umożliwiają bardzo skuteczne ograniczenie liczby parametrów, które trzeba wyliczyć. W tabeli \ref{tab:acustic_models} umieszczono zestawienie modeli akustycznych wytrenowanych na potrzeby eksperymentu, w kolumnie \textit{Liczba stanów} wpisano liczbę stanów, do jakiej ograniczono modele tri-fonowe. \\
		Poprzez \textit{Model z Ograniczonym Kontekstem} będziemy rozumieć akustyczny model tri-fonowy, w którym ograniczono liczbę stanów modelu Markova poprzez oba opisane powyżej mechanizmy.
		
		\begin{landscape}
			\begin{figure}[H]
			\centering
			\begin{tikzpicture}[node distance=1.7cm]
			
			\begin{scope}
						
			\def\x{1.5}
			\def\w{\x * 5}
			\def\z{\x * 2}
			\def\y{2.5}
			\def\j{4.0}
			
			\node [hmm2] (p1) {d-b+e};
			\node [hmm2, right = \x cm of p1] (p2) {a-b+c};
			\node [hmm2, below = \y cm of p2] (p3) {c-b+d};
			
			\node [hmm2, right = \z cm of p3] (p4) {k-l+m};
			
			\node [hmm2, right = \w cm of p2] (p5) {x-y+z};
			\node [hmm2, right = \x cm of p5] (p6) {w-y+t};
			\node [hmm2, below = \y cm of p5] (p7) {u-y+t};
			

			\draw [->] (p1) [out=270, in=140] to  (p3);
			\draw [->] (p2) [out=280, in=80] to  (p3);
			
			\draw [->] (p6) [out=270, in=40] to  (p7);
			\draw [->] (p5) [out=260, in=100] to  (p7);
			
			\node [hmm, below = \j cm of p3] (s1) {s1};
			\node [hmm, right = \x cm of s1] (s2) {s2};
			\node [hmm, right = \x cm of s2] (s3) {s3};
			\node [hmm, right = \x cm of s3] (s4) {s4};
			\node [hmm, right = \x cm of s4] (s5) {s5};
			
			\draw [->] (p3) [out=240, in=100] to (s1);
			\draw [->] (p3) [out=270, in=90]  to (s2);
			\draw [->] (p3) [out=300, in=130] to (s5);
			
			\draw [->] (p4) [out=240, in=80]  to (s1);
			\draw [->] (p4) [out=270, in=90]  to (s3);
			\draw [->] (p4) [out=300, in=100] to (s5);
			
			\draw [->] (p7) [out=240, in=50]  to (s1);
			\draw [->] (p7) [out=270, in=90]  to (s4);
			\draw [->] (p7) [out=300, in=80] to (s5);
			\end{scope}
			
			\end{tikzpicture}
			\caption{Mapowanie tri-fonów wirtualnych na tri-fony fizyczne}
			\label{fig:virtual_phisical_tri-phones}
			
		\end{figure}
	\end{landscape}
		
		
	\subsection{ Uczenie sieci NN estymującej prawdopodobieństwa stanów dla modeli z ograniczonym kontekstem }
		\subsubsection{ Redukowanie liczby stanów fizycznych w modelu }
		\subsubsection{ Wiązanie stanów logicznych ze stanami zisycznymi }
		\subsubsection{ Przygotowanie danych treningowych }
		\subsubsection{ Półautomatyczna weryfikacja poprawności danych treningowych }
		\subsubsection{ Wyznaczanie prawdopodobieństwa stanów apriori }
		\subsubsection{ Architektura konwolucyjnej sieci neuronowej }
		\subsubsection{ Kompletny algorytm przygotowania danych i uczenia sieci CNN }
		\subsubsection{ Znaczenie optymalizacji metaparametrów sieci/uczenia dla końcowej skuteczności ARM }	
	\subsection{ Teza pracy }

\section{ Wykorzystane technologie i biblioteki }
	\subsection{ Komponenty do budowy modeli akustycznych i językowych z pakietu HTK }
	\subsection{ Dekoder ARM Julius }
	\subsection{ Theano }
	\subsection{ Architektura systemu do eksperymentowania z wykorzystaniem sieci CNN }
		
\section{Opis danych}
	\label{sec:opis_danych}

	W celu przetestowania proponowanych metod wykorzystano studyjny korpus Clarin\footnote{http://mowa.clarin-pl.eu/korpusy/}. Składa się on z 56 godzin polskich nagrań o różnej tematyce, nagranych przez 554 różnych mówców. Każdy mówca nagrał 20 lub 30 wypowiedzi o długości od 6 do 22 sekund. Korpus nie jest zbalansowany pod względem płci. Wypowiedzi mają przypisane transkrypcje, jednak znajduje się w wiele błędów i artefaktów, takich jak zająknięcia (4. wypowiedz 191. mówcy), seplenienie (200. mówca) czy błędne odczytanie tekstu (18. wypowiedz 294. mówcy) skutkujące różnicą pomiędzy transkrypcja a faktycznie wypowiedzianymi słowami. Artefakty utrudniają lub wręcz uniemożliwiają wykorzystanie niektórych nagrań do uczenia modelu akustycznego. Dźwięk został nagrany z próbkowaniem 16 kHz i jakością 16 bitów na próbkę, a następnie zapisany w niekompresowanym formacie wav. Wypowiedzi zaczynają się i kończą ciszą. 
\\
W fazie wstępnego przetwarzania danych, nagrania zostały poddane następującym procesom:
\begin{itemize}
	\item automatyczne wyrównanie poziomu nagrań to stałego poziomu -6dB (1/2 maksymalnego możliwego do osiągnięcia poziomu) dla najgłośniejszych miejsc całego nagrania
	\item odrzucenie fragmentów ciszy/szumów tła o długości przekraczającej 0.7 sek,
	\item odrzucenie tych nagrań dla których faktycznie wypowiedziana fraza w znaczący sposób różniła się od frazy zadeklarowanej w dostarczonej transkrypcji.
\end{itemize}
W celu odrzucenia nagrań o niepoprawnej transkrypcji, przepuszczono je przez system do rozpoznawania mowy. Nagrania, których transkrypcje różniła się znacząco od wyniku rozpoznawania zostały odrzucone.

\section{Eksperymenty}


	\begin{figure}
	\begin{tabular}{|l|c|c|c|c|} \hline
		
		Nazwa modelu & \vtop{\hbox{\strut Min liczba}\hbox{\strut obserwacji}} &
		\vtop{\hbox{\strut Próg}\hbox{\strut poprawy}}& \vtop{\hbox{\strut Liczba}\hbox{\strut stanów /modeli}}& Skuteczność \\ \hline
		
		MODEL\_CL\_SUPERPURE & 100   & 350 & 4192 / 41309 & 81.58 \\
		MODEL\_CL\_25000     & 25000 & 350 & 304 / 8074   & 76.90 \\
		MODEL\_CL\_33000     & 33000 & 350 & 231          &   -   \\
		MODEL\_CL\_37000     & 37000 & 350 & 214 / 7775   & 74.97 \\
		???????              &   -   & 350 & 147          &   -   \\
		???????              &   -   & 350 & 122          &   -   \\
		MODEL\_UNIFONOWY     &  N/A  & N/A &     N/A      & 71.86 \\
		\hline
	\end{tabular}
	\caption{\label{tab:acustic_models}Wytrenowane modele akustyczne}
	\end{figure}

	 \begin{figure}
	 \begin{adjustwidth}{-1cm}{}
	\begin{tabular}{|c|c|c|c|c|c|c|} \hline
		
		Nazwa modelu & Liczba wyjść & Kontekst & \vtop{\hbox{\strut Parametry}\hbox{\strut pierwszego}\hbox{\strut przejścia}}  & 
		\vtop{\hbox{\strut Parametry}\hbox{\strut drugiego}\hbox{\strut przejścia}} & \vtop{\hbox{\strut Skuteczność}\hbox{\strut corr}} & \vtop{\hbox{\strut Skuteczność}\hbox{\strut acc}} \\
		\hline
		\multirow{7}{*}{Model 240424} &
		\multirow{7}{*}{-}            &
		\multirow{7}{*}{5}            & 13 -8 & 13 -9 & 84.88 & 81.09 \\	
									  &&& \textbf{12 -7} & \textbf{15 -9} & \textbf{85.47} & \textbf{81.55}\\
									  &&& 12 -7 & 12 -7 & 85.31 & 81.32 \\
									  &&& 11 -7 & 11 -7 & 85.16 & 81.03 \\
									  &&& 10 -7 & 10 -7 & 84.98 & 80.72 \\
									  &&& 7 -8  & 7 -8  & 82.8  & 78.19 \\
									  &&& 5 -8  & 5 -8  & 78.98 & 73.37 \\
		\hline
		\multirow{8}{*}{Model 268154} &
		\multirow{7}{*}{122}            &
		\multirow{8}{*}{5}          & \textbf{13 -8} & \textbf{13 -9} & \textbf{85.56} & \textbf{81.69} \\
									  &&& 12 -7 & 15 -9 & 86.92 & 81.48 \\
									  &&& 12 -7 & 12 -7 & 85.71 & 81.61 \\
									  &&& 11 -7 & 11 -7 & 85.72 & 81.50 \\
									  &&& 10 -7 & 10 -7 & 85.57 & 81.23 \\
									  &&& 7 -8  & 7 -8  & 83.24 & 78.47 \\
									  &&& 5 -8  & 5 -8  & 79.62 & 73.9  \\
									  &&& 18 -7 & 16 -12& 82.33 & 79.04 \\
		\hline					
		\multirow{7}{*}{Model 268151} &	
		\multirow{7}{*}{214}            &	  
		\multirow{7}{*}{5}          & 13 -8 & 13 -9 & 85.19 & 81.44 \\
									  &&& \textbf{12 -7} & \textbf{15 -9} & \textbf{88.58} & \textbf{83.39} \\
									  &&& 12 -7.5 & 15 -9.5&  88.44 & 83.33 \\
									  &&& 12 -7 16& -9.5   & 88.78  & 83.04 \\
									  &&& 12 -7 12& -7  & 84.98 & 81.09 \\ 
									  &&& 11 -7 11& -7  & 84.54 & 80.61 \\
									  &&& 18 -7 16& -12 & 82.88 & 79.76 \\
		\hline					
		\multirow{5}{*}{Model 268148} &	
		\multirow{7}{*}{304}            &	  
		\multirow{5}{*}{5} & 13 -8 & 13 -9 & 64.85 & 54.30 \\
									  &&& \textbf{12 -7} & \textbf{15 -9} & \textbf{71.22} & \textbf{57.42} \\
									  &&& 12 -7 & 12 -7 & 64.07 & 52.58 \\
									  &&& 7 -8  & 7 -8  & 54.39 & 39.58 \\
									  &&& 18 -7 & 16 -12& 62.64 & 55.14 \\
		\hline
		
	\end{tabular}
	\caption{\label{tab:text1}Wyniki cz.1}
	\end{adjustwidth}
	\end{figure}

	\begin{figure}
	\begin{adjustwidth}{-3.8cm}{}
	\begin{tabular}{|c|c|c|c|c|c|c|} \hline
		Nazwa modelu & Liczba wyjść & Kontekst & \vtop{\hbox{\strut Parametry}\hbox{\strut pierwszego}\hbox{\strut przejścia}}  & 
		\vtop{\hbox{\strut Parametry}\hbox{\strut drugiego}\hbox{\strut przejścia}} & \vtop{\hbox{\strut Skuteczność}\hbox{\strut corr}} & \vtop{\hbox{\strut Skuteczność}\hbox{\strut acc}} \\
		\hline
		\multirow{9}{*}{Model 268159} &
		\multirow{7}{*}{231}            &
		\multirow{9}{*}{5}          & 18 -7 & 16 -12 & 83.43 & 79.90 \\
		&&& 12 -7 & 15 -9  & 89.25 & 83.37 \\
		&&& 12 -7 & 15 -9  & 89.11 & 83.40 \\
		&&& \textbf{12 -10}& \textbf{15 -10} & \textbf{88.80} & \textbf{83.48} \\
		&&& 13 -10& 15 -10 & 88.10 & 83.37 \\
		&&& 7 -8  & 7 -8   & 79.79 & 74.63 \\
		&&& 12 -7 & 12 -7  & 85.22 & 80.68 \\
		&&& 13 -11& 15 -11 & 87.92 & 83.34 \\
		&&& 14 -12& 15 -12 & 86.24 & 82.19 \\
		\hline
		\multirow{7}{*}{Model 268158} &
		\multirow{7}{*}{147}            &
		\multirow{7}{*}{5}          & 18 -7 & 16 -12 & 82.88 & 79.64 \\
		&&& 12 -7 & 15 -9  & 88.56 & 83.18 \\
		&&& \textbf{12 -10}& \textbf{15 -10} & \textbf{88.17} & \textbf{83.24} \\
		&&& 7 -8  & 7 -8   & 73.31 & 78.59 \\
		&&& 11 -10& 11 -10 & 84.95 & 81.12 \\
		&&& 11 -9 & 11 -9  & 85.32 & 81.32 \\
		&&& 12 -9 & 12 -9  & 85.51 & 81.55 \\
		\hline
		MODEL\_CL\_33000, rectify        & 231 & 5 & 12 -10 & 15 -10 & 88.84 & 83.50 \\
		\hline
		MODEL\_CL\_33000, leaky\_rectify & 231 & 5 & 12 -10 & 15 -10 & 89.19 & 83.89 \\
		\hline
		MODEL\_CL\_33000, leaky\_rectify & 231 & 7 & 12 -10 & 15 -10 & 88.95 & 83.56 \\
		\hline
		MODEL\_CL\_33000, leaky\_rectify & 231 & 9 & 12 -10 & 15 -10 & 88.90 & 83.49 \\
		\hline
		MODEL\_CL\_33000, leaky\_rectify & 231 & 2 & 12 -10 & 15 -10 & 89.24 & 83.64 \\
		\hline
		
	\end{tabular}
	\end{adjustwidth}
	\caption{\label{tab:text2}Wyniki cz.2}
	\end{figure}


    Należy tutaj jasno określić cel przeprowadzanych badań i go uzasadnić. Uzasadnić potrrzebę dobrania optymalnych parametrów dekodowania, osobno dla GMM-HMM i CNN-HMM. Każdy z podpunktów musi kończyć się krótką analizą zaprezentowanych wyników oraz próbą ich uzasadnienia.
	\subsection{ Środowisko sprzętowo-programisytyczne }
	\subsection{ Optymalizacja parametrów procesu dekodowania }
	\subsection{ Wpływ sposobu wyznaczania cech na skuteczność rozpoznawania }
	Tutaj należy porównać skuteczność rozpoznawania dla cech MFCC i MFSC dla GMM-HMM i CNN-HMM oraz uzasadnić otrzymamy wynik (dla GMM lepsze MFCC, dla CNN lepsze MFSC)
	\subsection{Wpływ liczby fizycznych stanów na skuteczność rozpoznawania }
	Należy tutaj przetestować równocześnie (dla tych samych danych) model GMM-HMM i CNN-HMM, dla neutralnych parametrów lmp/lmp2 i dla parametrów optymalizowanych na zbiorze walidacyjnym
	\subsection{ Wpływ głębokości/architektury sieci na skuteczność rozpoznawania }
	\subsection{ Wpływ szerokości kontekstu na skuteczność rozpoznawania }
	\subsection{ Porównanie efektywności czasowej modeli GMM i CNN }

\section{ Podsumowanie }
  Tej sekcji zwykle nie dzieli się już na podsekcje Zqamieścić tutaj ocenę uzyskanych wyników, praktycznego znaczenia uzyskanych wyników, napotkane problemy, możliwe dalsze prace rozwojowe
   
   
	\nocite{*}
	\bibliographystyle{plain}
	\bibliography{bibliografia}
\end{document}